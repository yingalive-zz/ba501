{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ying Chen Python Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## First Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 How do you handle duplicate values in a dataset in Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll use duplicated() function to detect duplicates in Python.\n",
    "If there is duplicates in dataset indeed, I'll run the dataset.drop_duplicates() function to drop duplicates and return unique rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 Acceptance rate\n",
    "You are given two tables - friend_request and request_accepted. \n",
    "Friend_request contains requester_id, time and sent_to_id and request_accepted table contains time, acceptor_id and requestor_id. How will you determine the overall acceptance rate of requests?  Write in both Python and SQL. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For requests that have been sent several times (requests sent from the same requester_id and to the same id at different time), I consider them as the same requests and count them as once.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQL"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Return unique request table\n",
    "\n",
    "SELECT requester_id, sent_to_id, MIN(time) AS time\n",
    "INTO uniq_request\n",
    "FROM friend_request rq\n",
    "GROUP BY 1,2;\n",
    "\n",
    "# Join the two tables to check acceptance\n",
    "\n",
    "SELECT uq.requester_id AS requester_id, uq.sent_to_id AS sent_to_id\n",
    ", CASE WHEN acc.time IS NOT NULL THEN 1\n",
    "ELSE 0 END AS accept\n",
    "INTO check_table\n",
    "FROM uniq_request uq\n",
    "LEFT JOIN request_accepted acc\n",
    "ON uq.requester_id = acc.requestor_id\n",
    "    AND uq.sent_to_id = acc.acceptor_id\n",
    "    AND up.time < acc.time;\n",
    "    \n",
    "# Calculate acceptance rate, shown as %.\n",
    "SELECT SUM(accept)*100.0/COUNT(*) AS accpetance_rate\n",
    "FROM check_table;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[import pandas as pd\n",
    "# drop duplicates\n",
    "friend_request =friend_request.drop_duplicates(['requester_id','sent_to_id'])\n",
    "\n",
    "# join table\n",
    "accept_table = pd.merge(friend_request, request_accepted,how='left',left_on =['requester_id','sent_to_id'],right_on=\n",
    "['requestor_id','acceptor_id'])\n",
    "\n",
    "# calculate accpetance rate, shown as %\n",
    "def isNotNaN(num):\n",
    "    return num == num\n",
    "acceptance_rate = sum(isNotNaN(accept_table.requestor_id))/len(accept_table)*100.0\n",
    "print(acceptance_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 Dream company\n",
    "Do some research and summarize the business model of your dream company, or company that you interview with.\n",
    "\n",
    "**What** is the product\n",
    "\n",
    "**Who** are the customer\n",
    "\n",
    "**How** do they make money\n",
    "\n",
    "**Why** do you want to work for this company?\n",
    "\n",
    "(Optional) If you were CEO, what would you do to increase company’s revenue in the next 5 years?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Answer \n",
    "I'm currently interviewing with Etsy.\n",
    "\n",
    "#### Product\n",
    "\n",
    "Etsy provides a marketplace for people to buy and sell unique goods. All the sales are web/app based.\n",
    "I regard Etsy.com, Etsy APP(Buyer-side) and Sell on Etsy APP (Merchant-side) as its product.\n",
    "\n",
    "#### Customer\n",
    "\n",
    "Since Etsy is a double-margin marketplace, it's important for it to attract more consumers coming to buy products and having enough and various kind of merchants opening shops on Etsy.\n",
    "\n",
    "I regard Etsy merchants as its customers since it provides service and charges from merchants side.\n",
    "\n",
    "#### How to make money\n",
    "\n",
    "Etsy's business model is to create a marketplace and charges from the merchants' side. \n",
    "Thus, it offers a lot of services for merchants like creating homepage, back-end statistics, etc. \n",
    "Most importantly, it encourages merchants to purchase traffic, in other words, media buy on Etsy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Second Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 Write Function\n",
    "Similarly to PrintDailyTimeSeries() in the sample code, write a Python function called PrintCumulativeTimeSeries(). Specifically:\n",
    "\n",
    "The function takes three inputs:\n",
    "experiment_id\n",
    "country\n",
    "vertical\n",
    "\n",
    "The function produces two outputs:\n",
    "A time series chart showing the cumulative uplift (hint: search for cumsum)\n",
    "Print out the cumulative % uplift on revenue, experiment vs. control. Hint: (red - blue) / blue %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>spend_usd</th>\n",
       "      <th>user_id</th>\n",
       "      <th>vertical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JP</td>\n",
       "      <td>2017-04-02</td>\n",
       "      <td>12624548</td>\n",
       "      <td>5813140433216629693</td>\n",
       "      <td>16.138855</td>\n",
       "      <td>5006730028073359543</td>\n",
       "      <td>ANDROID_APPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>12624549</td>\n",
       "      <td>16333056276711034931</td>\n",
       "      <td>9.990000</td>\n",
       "      <td>5938685669571545259</td>\n",
       "      <td>ANDROID_APPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JP</td>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>12624548</td>\n",
       "      <td>11227119161741298366</td>\n",
       "      <td>19.887087</td>\n",
       "      <td>17623708458399141713</td>\n",
       "      <td>ANDROID_APPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>12624548</td>\n",
       "      <td>11927299833124210932</td>\n",
       "      <td>19.990000</td>\n",
       "      <td>18042812344456618148</td>\n",
       "      <td>ANDROID_APPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JP</td>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>12624549</td>\n",
       "      <td>11644727017708872749</td>\n",
       "      <td>88.220093</td>\n",
       "      <td>4325104700699531031</td>\n",
       "      <td>ANDROID_APPS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country       date  experiment_id              order_id  spend_usd  \\\n",
       "0      JP 2017-04-02       12624548   5813140433216629693  16.138855   \n",
       "1      US 2017-04-03       12624549  16333056276711034931   9.990000   \n",
       "2      JP 2017-04-04       12624548  11227119161741298366  19.887087   \n",
       "3      US 2017-04-03       12624548  11927299833124210932  19.990000   \n",
       "4      JP 2017-04-03       12624549  11644727017708872749  88.220093   \n",
       "\n",
       "                user_id      vertical  \n",
       "0   5006730028073359543  ANDROID_APPS  \n",
       "1   5938685669571545259  ANDROID_APPS  \n",
       "2  17623708458399141713  ANDROID_APPS  \n",
       "3  18042812344456618148  ANDROID_APPS  \n",
       "4   4325104700699531031  ANDROID_APPS  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# data location\n",
    "file_path ='/Users/Ying/Google Drive/Bittiger/BA501/Week 4 Python/02 实战课/'\n",
    "file_name ='BA501_python_data.csv'\n",
    "\n",
    "# date_parser\n",
    "import datetime as dt\n",
    "parser = lambda date: pd.datetime.strptime(date, '%Y%m%d')\n",
    "\n",
    "# read data\n",
    "data = pd.read_csv(file_path+file_name,parse_dates=[1],date_parser=parser)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-154-8f0a73aabd08>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-154-8f0a73aabd08>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    table = my_data[[\"date\", \"spend_usd\"]][my_data.experiment_id == my_id,\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Series' objects are mutable, thus they cannot be hashed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-174-48a64b0b257a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mPrintDailyTimeSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mPrintCumulativeTimeSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m12624548\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12624549\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"JP\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"ANDROID_APPS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-174-48a64b0b257a>\u001b[0m in \u001b[0;36mPrintCumulativeTimeSeries\u001b[0;34m(experiment_id, country, vertical)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mPrintDailyTimeSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mPrintCumulativeTimeSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m12624548\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12624549\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"JP\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"ANDROID_APPS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-174-48a64b0b257a>\u001b[0m in \u001b[0;36mPrintDailyTimeSeries\u001b[0;34m(my_data, experiment_id)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# data grouping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mmy_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"date\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mtreatment_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGetSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mcontrol_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGetSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-174-48a64b0b257a>\u001b[0m in \u001b[0;36mGetSeries\u001b[0;34m(my_data, my_id)\u001b[0m\n\u001b[1;32m      5\u001b[0m         table = my_data[[\"date\", \"spend_usd\"]][my_data.experiment_id == my_id,\n\u001b[1;32m      6\u001b[0m                                               \u001b[0mmy_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcountry\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcountrys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                               my_data.vertical==verticals]\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mseries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spend_usd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mseries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2060\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2062\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2064\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2067\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2069\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1530\u001b[0m         \u001b[0;34m\"\"\"Return the cached item, item represents a label indexer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_item_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m         raise TypeError('{0!r} objects are mutable, thus they cannot be'\n\u001b[0;32m--> 877\u001b[0;31m                         ' hashed'.format(self.__class__.__name__))\n\u001b[0m\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Series' objects are mutable, thus they cannot be hashed"
     ]
    }
   ],
   "source": [
    "def PrintCumulativeTimeSeries(experiment_id,country,vertical):\n",
    "    def GetSeries(my_data, my_id):\n",
    "        countrys = country\n",
    "        verticals = vertical\n",
    "        table = my_data[[\"date\", \"spend_usd\"]][my_data.experiment_id == my_id,\n",
    "                                              my_data.country == countrys,\n",
    "                                              my_data.vertical==verticals]\n",
    "        series = my_data.groupby('date')['spend_usd'].sum()\n",
    "        series = np.cumsum(series)\n",
    "        return(series)\n",
    "    \n",
    "    # plot\n",
    "    def PlotSeries(index_series, experiment_series, control_series):\n",
    "        df = pd.DataFrame(\n",
    "            {\n",
    "                \"experiment\": experiment_series.tolist(),\n",
    "                \"control\": control_series.tolist()\n",
    "            },\n",
    "            index = index_series, # a range of dates\n",
    "            columns = [\"experiment\", \"control\"]\n",
    "        )\n",
    "\n",
    "        plt.plot_date(x=df.index, y=df.experiment,fmt=\"r-\")\n",
    "        plt.plot_date(x=df.index, y=df.control,fmt=\"b-\")\n",
    "        plt.title(\"Daily Spend by Color\")\n",
    "        plt.ylabel(\"Daily Spend\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "    def PrintDailyTimeSeries(my_data,experiment_id):\n",
    "        # make sure our x-axis is consistent\n",
    "        date_series = my_data.date\n",
    "        index_series = np.unique(date_series) # unique date\n",
    "        index_series = np.sort(index_series) # sort by date\n",
    "\n",
    "        # data grouping\n",
    "        my_data = my_data.sort_values(\"date\", ascending=True, inplace=False)\n",
    "        treatment_series = GetSeries(my_data, experiment_id[0])\n",
    "        control_series = GetSeries(my_data, experiment_id[1])\n",
    "        \n",
    "        date_series = data.date\n",
    "        index_series = np.unique(date_series)\n",
    "        PlotSeries(index_series, treatment_series, control_series)\n",
    "        \n",
    "    ids = experiment_id\n",
    "    PrintDailyTimeSeries(data,ids)\n",
    "PrintCumulativeTimeSeries([12624548,12624549],\"JP\",\"ANDROID_APPS\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
